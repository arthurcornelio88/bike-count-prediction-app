# ğŸ“Š Data Ingestion Strategy - Final Decision

**Date**: 2025-10-11
**Version**: 2.0
**Status**: âœ… Validated by data quality analysis

---

## ğŸ¯ Executive Summary

After thorough data quality validation, we identified that all our data sources
(reference_data.csv, current_data.csv, and current_api_data.csv) originate from
**Paris Open Data historical exports**, ensuring perfect consistency.

**Final Decision**: Use `current_api_data.csv` (905k records, 2024-09-01 â†’ 2025-10-10)
as the unified baseline, complemented by daily live API ingestion starting 2025-10-11.

---

## âœ… Recommended Architecture

```text
PRODUCTION MLOps PIPELINE:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“¦ BASELINE (One-time setup)
â””â”€â”€ current_api_data.csv (905,740 records, 2024-09-01 â†’ 2025-10-10)
    â”‚
    â”œâ”€â”€ 80% TRAIN â†’ ~724k records (2024-09 â†’ 2025-08)
    â”‚   â””â”€â”€ Train legacy model (champion)
    â”‚
    â””â”€â”€ 20% TEST â†’ ~181k records (2025-08 â†’ 2025-10)
        â””â”€â”€ Fixed holdout for all model evaluations

ğŸ”„ DAILY OPERATIONS (Starting 2025-10-11)
â”œâ”€â”€ DAG fetch: API â†’ BigQuery.daily_YYYYMMDD (100 records/day)
â”œâ”€â”€ DAG predict: Champion model â†’ Predictions
â””â”€â”€ Store predictions for monitoring

ğŸ“Š WEEKLY MONITORING
â”œâ”€â”€ Aggregate last 7 days from BigQuery.daily_*
â”œâ”€â”€ Drift detection: Compare vs TEST set
â”œâ”€â”€ IF drift detected:
â”‚   â”œâ”€â”€ Fine-tune champion on last 30 days
â”‚   â”œâ”€â”€ Evaluate on SAME test set
â”‚   â””â”€â”€ Champion/Challenger decision
â””â”€â”€ ELSE: Keep champion

ğŸ“ˆ MONTHLY FULL RETRAIN (Optional)
â””â”€â”€ Retrain from scratch with updated train/test split
```

---

## ğŸ”‘ Key Advantages

| Aspect | Benefit |
|--------|---------|
| **Temporal Continuity** | Zero gap between test set (2025-10-10) and live API (2025-10-11) |
| **Fresh Baseline** | Test set represents current traffic patterns (vs 5-month gap with old split) |
| **Data Quality** | Perfect correlation (r=1.0) between all sources - same origin |
| **Seasonality** | Full year cycle coverage (Sep â†’ Oct) |
| **Drift Detection** | Accurate baseline for monitoring production data |
| **Single Source** | One consistent dataset from Paris Open Data |

---

## ğŸ“‹ Implementation Checklist

### Phase 1: Data Preparation âœ…

```bash
# 1. Create train/test split from current_api_data.csv (80/20)
python scripts/split_data_temporal.py

# Expected output:
# - train_baseline.csv: ~724k records (2024-09-01 â†’ 2025-08-15)
# - test_baseline.csv: ~181k records (2025-08-16 â†’ 2025-10-10)
```

![Split DS](img/split_ds.png)

### Phase 2: Version Control & Upload

```bash
# Upload to GCS raw_data/
gsutil -m cp data/train_baseline.csv gs://<your-bucket>/raw_data/train_baseline.csv
gsutil -m cp data/test_baseline.csv gs://<your-bucket>/raw_data/test_baseline.csv

# Track with DVC
dvc add data/train_baseline.csv data/test_baseline.csv
dvc push

# Commit DVC metadata
git add data/train_baseline.csv.dvc data/test_baseline.csv.dvc
git commit -m "chore: add new baseline splits from current_api_data"
```

### Phase 3: Train Champion Model (Local)

```bash
# Train champion model locally on train_baseline.csv
python scripts/train_legacy_model.py \
    --train data/train_baseline.csv \
    --test data/test_baseline.csv \
    --output models/champion_v1

# Expected metrics to beat:
# - MAE: < 15
# - RMSE: < 25
# - RÂ²: > 0.85

# Upload champion to MLflow/GCS for production use
```

**Note**: Champion model is trained locally once. Production will only perform fine-tuning on fresh data.

### Phase 4: BigQuery Setup

```bash
# Only daily API fetch will populate BigQuery (no historical baseline upload)
# BigQuery tables: bike_traffic_raw.daily_YYYYMMDD

# Schema auto-created by DAG fetch
# Data accumulates daily starting 2025-10-11
```

### Phase 5: Configure DAG Fetch

> To implement

### Phase 6: Weekly Monitoring DAG

> To implement

---

## ğŸ“Š Data Quality Validation Results

**Script**: [scripts/validate_overlap_data_quality.py](../scripts/validate_overlap_data_quality.py)
**Report**: [docs/overlap_data_quality_validation.json](overlap_data_quality_validation.json)

### Overlap Period Comparison (2024-09-01 â†’ 2025-05-17)

We compared historical CSV (reference + current) vs current_api_data.csv:

| Metric | Value | Interpretation |
|--------|-------|----------------|
| **Pearson correlation** | r = 1.0000 | **Perfect correlation** |
| **MAE** | 0.00 | Zero error - identical values |
| **MAPE** | 0.00% | No difference |
| **Match rate** | 100.0% | All records match |
| **KS test p-value** | 1.0000 | Identical distributions |
| **Matched records** | 563,765 / 563,815 | 99.99% overlap |

### Conclusion

All data sources are from **Paris Open Data historical exports**, downloaded at different
times but from the same origin. This ensures:

- âœ… Perfect data consistency
- âœ… No data quality issues
- âœ… Trustworthy for training and evaluation

---

## ğŸ”„ DataOps Workflow

### Daily Operations

**Complete Daily Pipeline** (DAG 1 â†’ DAG 2):

```mermaid
graph TB
    subgraph "DAG 1: Data Ingestion (06:00 UTC)"
        A[Paris Open Data API] -->|fetch up to 1000 records| B[Deduplication Logic]
        B -->|filter existing records| C[BigQuery comptage_velo]
        C -->|validate ingestion| D[Validation Task]
    end

    subgraph "DAG 2: Predictions (07:00 UTC)"
        D -->|trigger after ingestion| E[Check Raw Data]
        E -->|query last 48h| F[Transform for API]
        F -->|POST /predict| G[Champion Model]
        G -->|predictions + metadata| H[BigQuery predictions.daily_YYYYMMDD]
        H -->|validate count + metrics| I[Validation Task]
        I -->|send Discord alert| J[Monitoring]
    end

    subgraph "Model Loading"
        K[GCS summary.json] -->|get champion run_id| G
        L[MLflow Server] -->|load model artifacts| G
    end
```

**Key Flow Details:**

1. **DAG 1 (06:00)**: Fetches fresh data, deduplicates against existing records, stores in partitioned table
2. **DAG 2 (07:00)**: Runs 1h after ingestion, queries last 48h window, generates predictions with current champion
3. **Champion Tracking**: Every prediction tagged with `model_version` (MLflow run_id) for full traceability

---

## ğŸ“š Appendix: Previous Analysis Context

<details>
<summary>Click to expand: Initial temporal continuity audit</summary>

### Initial Audit Results

We initially explored using reference_data.csv + current_data.csv (948k records,
2024-04 â†’ 2025-05) with live API ingestion starting 2025-05-18.

#### Discovered Issues

1. **5-month gap** between test set (May 2025) and current date (October 2025)
2. **Outdated baseline** for drift detection
3. **Seasonality mismatch** (test set from spring, production in fall)

#### Solution

Use current_api_data.csv instead, which extends to 2025-10-10, eliminating the gap.

### Temporal Coverage

| Dataset | Period | Records | Status |
|---------|--------|---------|--------|
| reference_data.csv | 2024-04 â†’ 2025-01 | 660k | âš ï¸ Superseded |
| current_data.csv | 2025-01 â†’ 2025-05 | 287k | âš ï¸ Superseded |
| **current_api_data.csv** | 2024-09 â†’ 2025-10 | 905k | âœ… **New baseline** |

</details>

<details>
<summary>Click to expand: BigQuery architecture details</summary>

### BigQuery Structure

```text
PROJECT: datascientest-460618
â””â”€â”€ DATASET: bike_traffic_raw
    â”œâ”€â”€ historical_baseline          â† One-time load (train_baseline.csv)
    â”‚   â””â”€â”€ 724k records (2024-09-01 â†’ 2025-08-15)
    â”‚
    â”œâ”€â”€ daily_20251011               â† Daily API ingestion
    â”œâ”€â”€ daily_20251012
    â”œâ”€â”€ daily_...
    â”‚   â””â”€â”€ ~100 records/day
    â”‚
    â””â”€â”€ all_data (VIEW)              â† Union view
        â””â”€â”€ SELECT * FROM historical_baseline
            UNION ALL
            SELECT * FROM `daily_*`
```

### Unified Schema

| Column | Type | Source |
|--------|------|--------|
| `comptage_horaire` | INTEGER | Bike count/hour |
| `date_et_heure_de_comptage` | TIMESTAMP | Count timestamp |
| `identifiant_du_compteur` | STRING | Counter ID |
| `nom_du_compteur` | STRING | Counter name |
| `coordonnees_geographiques` | STRING | "lat, lon" format |
| `ingestion_ts` | TIMESTAMP | Ingestion time |

</details>

---

**Date**: 2025-11-06
**Version**: 2.0
**Status**: âœ… Strategy finalized based on data quality analysis
