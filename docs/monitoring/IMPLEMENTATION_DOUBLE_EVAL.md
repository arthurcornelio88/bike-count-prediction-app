# ImplÃ©mentation: Double Evaluation Metrics - Guide Complet

**Date**: 2025-11-04
**Status**: âœ… DEPLOYED
**DurÃ©e estimÃ©e**: 30 min

> **Note**: This implementation has been completed. All metrics, dashboards, and alerts
> have been updated to use the 4-metric double-evaluation system.

---

## ðŸ“‹ RÃ©sumÃ© des Changements

Ajout de **4 mÃ©triques RÂ² complÃ¨tes** pour la double Ã©valuation:

```text
bike_model_r2_champion_baseline    # Champion sur test_baseline
bike_model_r2_champion_current     # Champion sur test_current
bike_model_r2_challenger_baseline  # Challenger sur test_baseline
bike_model_r2_challenger_current   # Challenger sur test_current
```

**Backward compatibility**: Les anciennes mÃ©triques (`bike_model_r2_production`, `bike_prediction_r2`) sont conservÃ©es.

---

## ðŸ”§ Fichiers ModifiÃ©s

### 1. `monitoring/custom_exporters/airflow_exporter.py`

**Changements**:

- âœ… Ajout de 4 Gauges Prometheus (lignes 123-139)
- âœ… Modification de `_collect_monitoring_metrics()` (lignes 443-492)
- âœ… Ajout de `champion_r2_baseline` Ã  la query BigQuery (ligne 262)
- âœ… Ajout au dict `metrics` retournÃ© (ligne 285)

**Impact**: Expose les 4 RÂ² vers Prometheus

---

### 2. `dags/dag_monitor_and_train.py`

**Changements**:

- âœ… Pull de `champion_r2_baseline` depuis XCom (lignes 685-687)
- âœ… Ajout au default si training pas exÃ©cutÃ© (ligne 703)
- âœ… Ajout au `audit_record` (lignes 733-735)

**Impact**: BigQuery audit logs contient maintenant `champion_r2_baseline`

---

### 3. `monitoring/add_champion_r2_baseline_column.sql` (NOUVEAU)

Script SQL pour ajouter la colonne Ã  BigQuery.

---

## ðŸš€ ProcÃ©dure de DÃ©ploiement

### Ã‰tape 1: Ajouter la colonne BigQuery (5 min)

```bash
# Se connecter Ã  BigQuery via gcloud CLI
gcloud auth login

# ExÃ©cuter le script SQL
bq query --use_legacy_sql=false < monitoring/add_champion_r2_baseline_column.sql

# VÃ©rifier que la colonne existe
bq show --schema datascientest-460618:monitoring_audit.logs | grep champion_r2_baseline
```

**Attendu**: Colonne `champion_r2_baseline FLOAT64` ajoutÃ©e

---

### Ã‰tape 2: RedÃ©marrer Airflow Exporter (2 min)

```bash
# Rebuild le container avec les nouveaux Gauges
docker compose --profile monitoring build airflow-exporter

# RedÃ©marrer
docker compose --profile monitoring up -d airflow-exporter

# VÃ©rifier les logs
docker logs airflow-exporter --tail 50

# VÃ©rifier les mÃ©triques exposÃ©es
curl http://localhost:9101/metrics | grep "bike_model_r2"
```

**Attendu**: 6 mÃ©triques RÂ² exposÃ©es (4 nouvelles + 2 legacy)

---

### Ã‰tape 3: RedÃ©marrer Airflow Webserver/Scheduler (2 min)

```bash
# Rebuild avec le DAG modifiÃ©
docker compose restart airflow-webserver airflow-scheduler

# VÃ©rifier que le DAG charge sans erreur
docker logs airflow-scheduler --tail 50 | grep "monitor_and_fine_tune"
```

**Attendu**: Pas d'erreur de parsing DAG

---

### Ã‰tape 4: VÃ©rification End-to-End (10 min)

#### 4.1 DÃ©clencher un run de training

```bash
# Trigger le DAG monitor_and_fine_tune
docker exec airflow-webserver airflow dags trigger monitor_and_fine_tune

# Ou via UI: http://localhost:8081 â†’ monitor_and_fine_tune â†’ Trigger DAG
```

#### 4.2 VÃ©rifier les logs Airflow

```bash
# Attendre que le DAG termine (~5-10 min)
docker logs airflow-scheduler -f | grep "champion_r2_baseline"
```

**Attendu**:

```text
Champion RÂ² (test_baseline): 0.8670
Champion RÂ² (test_current): 0.7500
Challenger RÂ² (test_baseline): 0.6000
Challenger RÂ² (test_current): 0.7800
```

#### 4.3 VÃ©rifier BigQuery

```sql
SELECT
    timestamp,
    r2,                     -- Champion current (validate_model)
    champion_r2_baseline,   -- NEW!
    r2_baseline,            -- Challenger baseline
    r2_current,             -- Challenger current
    deployment_decision
FROM `datascientest-460618.monitoring_audit.logs`
ORDER BY timestamp DESC
LIMIT 5;
```

**Attendu**: Colonne `champion_r2_baseline` remplie avec valeurs non-NULL

#### 4.4 VÃ©rifier Prometheus

```bash
# Attendre 60s (cache airflow_exporter)
sleep 60

# Query Prometheus
curl "http://localhost:9090/api/v1/query?query=bike_model_r2_champion_baseline" | jq '.data.result[0].value'
curl "http://localhost:9090/api/v1/query?query=bike_model_r2_champion_current" | jq '.data.result[0].value'
curl "http://localhost:9090/api/v1/query?query=bike_model_r2_challenger_baseline" | jq '.data.result[0].value'
curl "http://localhost:9090/api/v1/query?query=bike_model_r2_challenger_current" | jq '.data.result[0].value'
```

**Attendu**: Les 4 mÃ©triques retournent des valeurs > 0

---

## ðŸ“Š Ã‰tape 5 (Optionnel): Dashboards Grafana

**Note**: Les dashboards existants continuent de fonctionner (backward compatibility).

Pour ajouter les nouveaux graphes "fair comparison":

1. Ouvrir [http://localhost:3000](http://localhost:3000)
2. CrÃ©er un nouveau dashboard "Double Evaluation - Fair Comparison"
3. Ajouter 2 panels:

### Panel 1: Both Models on test_baseline

```promql
bike_model_r2_champion_baseline   # Legend: "Champion (baseline)"
bike_model_r2_challenger_baseline  # Legend: "Challenger (baseline)"
```

**InterprÃ©tation**:

- Si Challenger < 0.60 â†’ RÃ©gression dÃ©tectÃ©e â†’ REJECT
- Sinon, continuer la comparaison

### Panel 2: Both Models on test_current

```promql
bike_model_r2_champion_current     # Legend: "Champion (current)"
bike_model_r2_challenger_current   # Legend: "Challenger (current)"
```

**InterprÃ©tation**:

- Si Challenger > Champion â†’ AmÃ©lioration â†’ DEPLOY
- Sinon â†’ SKIP

---

## âœ… Checklist de Validation

### Base Requirements

- [ ] Colonne `champion_r2_baseline` existe dans BigQuery
- [ ] Airflow Exporter redÃ©marrÃ© sans erreurs
- [ ] Airflow Scheduler/Webserver redÃ©marrÃ©s sans erreurs
- [ ] DAG `monitor_and_fine_tune` charge sans erreur

### Functional Tests

- [ ] DAG run complÃ©tÃ© avec succÃ¨s
- [ ] Logs Airflow montrent les 4 RÂ² values
- [ ] BigQuery `monitoring_audit.logs` contient `champion_r2_baseline` non-NULL
- [ ] Prometheus expose `bike_model_r2_champion_baseline`
- [ ] Prometheus expose `bike_model_r2_champion_current`
- [ ] Prometheus expose `bike_model_r2_challenger_baseline`
- [ ] Prometheus expose `bike_model_r2_challenger_current`
- [ ] MÃ©triques legacy (`bike_model_r2_production`, `bike_prediction_r2`) toujours fonctionnelles

### Grafana (Optionnel)

- [ ] Dashboard "Double Evaluation" crÃ©Ã©
- [ ] Panel "test_baseline comparison" affiche les 2 modÃ¨les
- [ ] Panel "test_current comparison" affiche les 2 modÃ¨les

---

## ðŸ”„ Rollback (si problÃ¨me)

### Rollback Airflow Exporter

```bash
# Revert les changements
git checkout HEAD~1 monitoring/custom_exporters/airflow_exporter.py

# Rebuild + restart
docker compose --profile monitoring build airflow-exporter
docker compose --profile monitoring up -d airflow-exporter
```

### Rollback DAG

```bash
# Revert
git checkout HEAD~1 dags/dag_monitor_and_train.py

# Restart
docker compose restart airflow-webserver airflow-scheduler
```

### Rollback BigQuery (si table recrÃ©Ã©e)

**Note**: Si vous avez utilisÃ© `ALTER TABLE ADD COLUMN`, pas besoin de rollback (colonne vide ne gÃªne pas).

Si vous avez `DROP TABLE`, restaurer depuis backup:

```bash
# Voir les backups disponibles
bq ls --transfer_config datascientest-460618

# Restaurer (Ã  adapter selon backup)
# bq restore ...
```

---

## ðŸ“ˆ RÃ©sultats Attendus AprÃ¨s DÃ©ploiement

### Avant (Ã©tat actuel)

```bash
curl http://localhost:9101/metrics | grep "bike.*r2"
# bike_model_r2_production 0.867
# bike_prediction_r2 0.528
```

**ProblÃ¨me**: 2 mÃ©triques seulement, comparaison sur test sets diffÃ©rents

---

### AprÃ¨s (Ã©tat corrigÃ©)

```bash
curl http://localhost:9101/metrics | grep "bike.*r2"
# bike_model_r2_production 0.867              # Legacy (Champion current)
# bike_prediction_r2 0.528                     # Legacy (Challenger current)
# bike_model_r2_champion_baseline 0.867        # NEW
# bike_model_r2_champion_current 0.750         # NEW
# bike_model_r2_challenger_baseline 0.600      # NEW
# bike_model_r2_challenger_current 0.780       # NEW
```

**BÃ©nÃ©fice**: 6 mÃ©triques, comparaisons Ã©quitables possibles

---

## ðŸ†˜ Troubleshooting

### ProblÃ¨me 1: Colonne BigQuery n'existe pas

**SymptÃ´me**: Logs airflow_exporter affichent `Error querying BigQuery audit table: column champion_r2_baseline not found`

**Solution**:

```bash
# ExÃ©cuter le script SQL
bq query --use_legacy_sql=false < monitoring/add_champion_r2_baseline_column.sql
```

---

### ProblÃ¨me 2: MÃ©triques Prometheus = 0

**SymptÃ´me**: `bike_model_r2_champion_baseline{} 0`

**Causes possibles**:

1. BigQuery colonne vide (pas encore de run DAG)
2. Airflow Exporter cache (attendre 60s)
3. DAG n'a pas encore pusher la valeur dans BigQuery

**Solution**:

```bash
# Trigger un nouveau run
docker exec airflow-webserver airflow dags trigger monitor_and_fine_tune

# Attendre que le DAG termine
# Attendre 60s pour le cache exporter
sleep 60

# Re-check
curl http://localhost:9101/metrics | grep champion_r2_baseline
```

---

### ProblÃ¨me 3: DAG Ã©choue avec KeyError

**SymptÃ´me**: Task `end_monitoring` fail avec `KeyError: 'champion_r2_baseline'`

**Cause**: Le XCom `champion_r2_baseline` n'est pas pusher par `fine_tune_model`

**Solution**: VÃ©rifier que le code Ã 
[dag_monitor_and_train.py:591-593](dags/dag_monitor_and_train.py#L591-L593)
push bien la valeur:

```python
context["ti"].xcom_push(
    key="champion_r2_baseline",
    value=float(champion_r2_baseline) if champion_r2_baseline else None,
)
```

---

## ðŸ“š RÃ©fÃ©rences

- [AUDIT_DOUBLE_EVAL.md](./AUDIT_DOUBLE_EVAL.md) - Rapport d'audit complet
- [01_architecture.md](./01_architecture.md) - Architecture monitoring
- [03_metrics_reference.md](./03_metrics_reference.md) - RÃ©fÃ©rence mÃ©triques
- [dags/dag_monitor_and_train.py](../../dags/dag_monitor_and_train.py) - Code DAG
- [monitoring/custom_exporters/airflow_exporter.py](../../monitoring/custom_exporters/airflow_exporter.py) - Code exporter

---

## âœ… Validation Finale

Une fois toutes les Ã©tapes complÃ©tÃ©es:

```bash
# Test complet
echo "=== 1. BigQuery Schema ==="
bq show --schema datascientest-460618:monitoring_audit.logs | grep champion_r2_baseline

echo "=== 2. Prometheus Metrics ==="
curl -s http://localhost:9101/metrics | grep "bike_model_r2" | wc -l  # Should be 6

echo "=== 3. Latest Values ==="
curl -s "http://localhost:9090/api/v1/query?query=bike_model_r2_champion_baseline" | jq '.data.result[0].value[1]'
curl -s "http://localhost:9090/api/v1/query?query=bike_model_r2_champion_current" | jq '.data.result[0].value[1]'
curl -s "http://localhost:9090/api/v1/query?query=bike_model_r2_challenger_baseline" | jq '.data.result[0].value[1]'
curl -s "http://localhost:9090/api/v1/query?query=bike_model_r2_challenger_current" | jq '.data.result[0].value[1]'

echo "=== 4. BigQuery Latest Row ==="
bq query --use_legacy_sql=false --format=prettyjson "
SELECT timestamp, r2, champion_r2_baseline, r2_baseline, r2_current
FROM \`datascientest-460618.monitoring_audit.logs\`
ORDER BY timestamp DESC
LIMIT 1
"
```

**Attendu**: Toutes les commandes retournent des valeurs valides (pas d'erreurs, pas de NULL).

---

**Status**: ðŸŽ¯ Ready to Deploy - Tous les fichiers modifiÃ©s, procÃ©dure documentÃ©e
